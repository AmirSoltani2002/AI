{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment:\n",
    "The enviroment consists of 7 in 9 cells. Each cell contains either food, wall or is empty. Agent is placed in first row and first column. The task in find the best policy for agent to collect all foods with minimum hitting to walls and not to be captured by ghost.\n",
    "### Rewards:\n",
    "Wall cell has -2 reward, foods has +1 reward and empty cell has -1 reward. Eating food where there is ghost, has -40 reward. If there pacman goes to empty cell where there is ghost, reward is -50. If pacman goes to cell where there is ghost and wall, reward is -5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from pygame.locals import *\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Enviroment and Game Functions:\n",
    "In Env class, all the game data, such as rewards, position of walls, position of foods, position of agent, position of ghost and rules of its walking, Q-table, rules of game, training and testing agent is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "  \"\"\"\n",
    "  Initialization of map, gamma, alpha, epsilon and Q-table is done in init function.\n",
    "  \"\"\"\n",
    "  def __init__(self, row, col, lamda, alpha, epsilon = 0.9, reward = 2):\n",
    "    self.col = col\n",
    "    self.row = row\n",
    "    self.reward = np.ones((row, col))\n",
    "    self.reward[0, 0] = 0\n",
    "    self.Q = np.zeros((4, 8**8))\n",
    "    self.lamda = lamda\n",
    "    self.alpha = alpha\n",
    "    self.epsilon = epsilon\n",
    "    self.current_row = 0\n",
    "    self.current_col = 0\n",
    "    self.food = row * col\n",
    "    self.curr_food = 0\n",
    "    self.current_reward = 0\n",
    "  \n",
    "  \"\"\"Specifies how ghost is moved\"\"\"\n",
    "  def ghost_move(self):\n",
    "    self.ghost_map[self.ghost_row, self.ghost_col] = 0\n",
    "    row = np.random.randint(-1, 2)\n",
    "    col = np.random.randint(-1, 2)\n",
    "    self.ghost_row = self.ghost_row + row if 0<=(self.ghost_row + row)<self.row else self.ghost_row\n",
    "    self.ghost_col = self.ghost_col + col if 0<=(self.ghost_col + col)<self.col else self.ghost_col\n",
    "    self.ghost_map[self.ghost_row, self.ghost_col] = 1\n",
    "\n",
    "  \"\"\"\n",
    "  Use this function to reset map to its initialized status for new episod.\n",
    "  \"\"\"\n",
    "  def reset_map(self):\n",
    "    self.add_ghost(self.init_g_row, self.init_g_col)\n",
    "    self.reward = np.ones((self.row, self.col))\n",
    "    self.reward[0, 0] = 0\n",
    "    self.add_wall(self.wall_pos, True)\n",
    "\n",
    "  \"\"\"\n",
    "  Use this to add wall to map.\n",
    "  \"\"\"\n",
    "  def add_wall(self, positions, update = False, reward = -2):\n",
    "    self.wall_pos = positions\n",
    "    self.reward[positions[:, 0], positions[:, 1]] = reward\n",
    "    if not update:\n",
    "      self.food -= (positions.shape[0] + 1)\n",
    "\n",
    "  \"\"\"\n",
    "  Use this to add ghost\n",
    "  \"\"\"\n",
    "  def add_ghost(self, row, col):\n",
    "    self.ghost_map = np.zeros((self.row, self.col))\n",
    "    self.init_g_row = row\n",
    "    self.init_g_col = col\n",
    "    self.ghost_row = row\n",
    "    self.ghost_col = col\n",
    "    self.ghost_map[self.ghost_row, self.ghost_col] = 1\n",
    "\n",
    "  \"\"\"\n",
    "  This function returns the state of agent based on current status of map and its position in the map.\n",
    "  \"\"\"\n",
    "  def state(self, row, col):#0->boundary, 1->food, 2->empty, 3->wall\n",
    "    d_r = u_r = u_l = d_l = down = right = up = left = 0\n",
    "    if row != self.row-1:\n",
    "      if self.reward[row+1, col] == 1: down = 1\n",
    "      elif self.reward[row+1, col] == 0: down = 2\n",
    "      else: down = 3\n",
    "      if self.ghost_map[row+1, col] == 1: down += 4\n",
    "    if col != self.col-1:\n",
    "      if self.reward[row, col+1] == 1: right = 1\n",
    "      elif self.reward[row, col+1] == 0: right = 2\n",
    "      else: right = 3\n",
    "      if self.ghost_map[row, col+1] == 1: right += 4\n",
    "    if row != 0:\n",
    "      if self.reward[row-1, col] == 1: up = 1\n",
    "      elif self.reward[row-1, col] == 0: up = 2\n",
    "      else: up = 3\n",
    "      if self.ghost_map[row-1, col] == 1: up += 4\n",
    "    if col != 0:\n",
    "      if self.reward[row, col-1] == 1: left = 1\n",
    "      elif self.reward[row, col-1] == 0: left = 2\n",
    "      else: left = 3\n",
    "      if self.ghost_map[row, col-1] == 1: left += 4\n",
    "    if down != 0 and right != 0:\n",
    "      if self.reward[row+1, col+1] == 1: d_r = 1\n",
    "      elif self.reward[row+1, col+1] == 0: d_r = 2\n",
    "      else: d_r = 3\n",
    "      if self.ghost_map[row+1, col+1] == 1: d_r += 4\n",
    "    if up != 0 and right != 0:\n",
    "      if self.reward[row-1, col+1] == 1: u_r = 1\n",
    "      elif self.reward[row-1, col+1] == 0: u_r = 2\n",
    "      else: u_r = 3\n",
    "      if self.ghost_map[row-1, col+1] == 1: u_r += 4\n",
    "    if up != 0 and left != 0:\n",
    "      if self.reward[row-1, col-1] == 1: u_l = 1\n",
    "      elif self.reward[row-1, col-1] == 0: u_l = 2\n",
    "      else: u_l = 3\n",
    "      if self.ghost_map[row-1, col-1] == 1: u_l += 4\n",
    "    if down != 0 and left != 0:\n",
    "      if self.reward[row+1, col-1] == 1: d_l = 1\n",
    "      elif self.reward[row+1, col-1] == 0: d_l = 2\n",
    "      else: d_l = 3\n",
    "      if self.ghost_map[row+1, col-1] == 1: d_l += 4\n",
    "    return (8**7*down + 8**6*right + up * 8**5 + left * 8**4 + d_r * 8**3 + u_r * 8 ** 2 + u_l * 8 + d_l)\n",
    "\n",
    "  \"\"\"\n",
    "  Check if what actions are invalid in particular state.\n",
    "  \"\"\"\n",
    "  def check_move(self):\n",
    "    for j in range(self.Q.shape[1]):\n",
    "      res = self.check_state(j)\n",
    "      for i in range(4):\n",
    "        if res[i] == 0:\n",
    "          self.Q[i, j] = -np.inf\n",
    "\n",
    "  \"\"\"\n",
    "  Map state number to a quaternary number with length 8 to observe what is around agent.\n",
    "  \"\"\"\n",
    "  def check_state(self, state):\n",
    "    num = state\n",
    "    res = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    i = 0\n",
    "    while num > 0:\n",
    "      res[7 - i] = num % 8\n",
    "      i += 1\n",
    "      num //= 8\n",
    "    return res\n",
    "\n",
    "  \"\"\"\n",
    "  Return reward based on the current action and state.\n",
    "  \"\"\"\n",
    "  def action_reward(self, state, action):\n",
    "    res = self.check_state(state)\n",
    "    if action == 0:\n",
    "      if res[action] == 1:\n",
    "        self.current_row += 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return 2\n",
    "      elif res[action] == 2:\n",
    "        self.current_row += 1\n",
    "        return -1\n",
    "      elif res[action] == 3:\n",
    "        return -2\n",
    "      elif res[action] == 5:\n",
    "        self.current_row += 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return -40\n",
    "      elif res[action] == 6:\n",
    "        self.current_row += 1\n",
    "        return -50\n",
    "      elif res[action] == 7:\n",
    "        return -5\n",
    "\n",
    "    elif action == 1:\n",
    "      if res[action] == 1:\n",
    "        self.current_col += 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return 2\n",
    "      elif res[action] == 2:\n",
    "        self.current_col += 1\n",
    "        return -1\n",
    "      elif res[action] == 3:\n",
    "        return -2\n",
    "      elif res[action] == 5:\n",
    "        self.current_col += 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return -40\n",
    "      elif res[action] == 6:\n",
    "        self.current_col += 1\n",
    "        return -50\n",
    "      elif res[action] == 7:\n",
    "        return -5\n",
    "\n",
    "    elif action == 2:\n",
    "      if res[action] == 1:\n",
    "        self.current_row -= 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return 2\n",
    "      elif res[action] == 2:\n",
    "        self.current_row -= 1\n",
    "        return -1\n",
    "      elif res[action]== 3:\n",
    "        return -2\n",
    "      elif res[action] == 5:\n",
    "        self.current_row -= 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return -40\n",
    "      elif res[action] == 6:\n",
    "        self.current_row -= 1\n",
    "        return -50\n",
    "      elif res[action] == 7:\n",
    "        return -5\n",
    "\n",
    "    elif action == 3:\n",
    "      if res[action] == 1:\n",
    "        self.current_col -= 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return 2\n",
    "      elif res[action] == 2:\n",
    "        self.current_col -= 1\n",
    "        return -1\n",
    "      elif res[action] == 3:\n",
    "        return -2\n",
    "      elif res[action] == 5:\n",
    "        self.current_col -= 1\n",
    "        self.curr_food += 1\n",
    "        self.reward[self.current_row, self.current_col] = 0\n",
    "        return -40\n",
    "      elif res[action] == 6:\n",
    "        self.current_col -= 1\n",
    "        return -50\n",
    "      elif res[action] == 7:\n",
    "        return -5\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  Move agent from current state to a random state or base state, depends on epsilon value.\n",
    "  \"\"\"\n",
    "  def move(self, state):\n",
    "    actions = self.Q[:, state]\n",
    "    action = 0\n",
    "    if np.random.random() < self.epsilon:\n",
    "      while True:\n",
    "        action = np.random.randint(0, 4)\n",
    "        if actions[action] != -np.inf:\n",
    "          break\n",
    "    else:\n",
    "      action = np.where(actions == max(actions))[0][0]\n",
    "    reward = self.action_reward(state, action)\n",
    "    self.current_reward += reward\n",
    "    next_state = self.state(self.current_row, self.current_col)\n",
    "    self.Q[action, state] += self.alpha * (reward + self.lamda * max(self.Q[:, next_state]) - self.Q[action, state])\n",
    "\n",
    "  def episod(self):\n",
    "    self.current_row = 0\n",
    "    self.current_col = 0\n",
    "    iteration = 0\n",
    "    while self.curr_food < self.food:\n",
    "      self.ghost_move()\n",
    "      state = self.state(self.current_row, self.current_col)\n",
    "      self.move(state)\n",
    "      iteration += 1\n",
    "      if self.current_col == self.ghost_col and self.current_row == self.ghost_row:\n",
    "        break\n",
    "    return iteration\n",
    "\n",
    "  \"\"\"\n",
    "  Use this to do a compelete episod.\n",
    "  \"\"\"\n",
    "  def game(self):\n",
    "    i = 0\n",
    "    c = 1.01\n",
    "    self.check_move()\n",
    "    while i < 300:\n",
    "      self.reset_map()\n",
    "      self.epsilon =  self.epsilon / c**i\n",
    "      self.episod()\n",
    "      self.current_reward = 0\n",
    "      self.curr_food = 0\n",
    "      i += 1\n",
    "\n",
    "  \"\"\"\n",
    "  Use this function to visualy test pacman in trained model\n",
    "  \"\"\"\n",
    "  def test_game(self):\n",
    "    pygame.init()\n",
    "    # Set up the display\n",
    "    cell_size = 100  # Size of each cell in pixels\n",
    "    map_width = self.col  # Number of cells in the horizontal direction\n",
    "    map_height = self.row # Number of cells in the vertical direction\n",
    "    screen_width = cell_size * map_width\n",
    "    screen_height = cell_size * map_height\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "    pygame.display.set_caption(\"Pacman\")\n",
    "    # Define colors\n",
    "    WHITE = (255, 255, 255)\n",
    "    BLACK = (0, 0, 0)\n",
    "    BLUE = (0, 0, 255)\n",
    "    self.reset_map()\n",
    "    self.current_reward = 0\n",
    "    self.curr_food = 0\n",
    "    self.current_row = 0\n",
    "    self.current_col = 0\n",
    "    last_x = last_y = 0\n",
    "    self.epsilon = 0.05\n",
    "    last_food = 0\n",
    "    iterate_last_food = 0\n",
    "    while self.curr_food < self.food:\n",
    "        self.ghost_move()\n",
    "        state = self.state(self.current_row, self.current_col)\n",
    "        self.move(state)\n",
    "        pacman_map = self.reward\n",
    "        screen.fill(BLACK)\n",
    "        # Render the map\n",
    "        running = True\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        if not running:\n",
    "            break\n",
    "        for x in range(map_height):\n",
    "            for y in range(map_width):\n",
    "                cell_color = WHITE\n",
    "                if pacman_map[x][y] == -2:\n",
    "                    cell_color = BLACK\n",
    "                if pacman_map[x][y] == 1:\n",
    "                    cell_color = BLUE\n",
    "                rectangle = pygame.Rect(y * cell_size, x * cell_size, cell_size, cell_size)\n",
    "                pygame.draw.rect(screen, cell_color, rectangle)\n",
    "                if x == self.current_row and y == self.current_col:\n",
    "                    if last_x > self.current_row:\n",
    "                        image = pygame.image.load(\"up_pac.png\")  # Replace \"image.jpg\" with the path to your image file\n",
    "                    elif last_x < self.current_row:\n",
    "                        image = pygame.image.load(\"bottom_pac.png\") \n",
    "                    elif last_y < self.current_col:\n",
    "                        image = pygame.image.load(\"right_pac.png\") \n",
    "                    elif last_y > self.current_col:\n",
    "                        image = pygame.image.load(\"left_pac.png\") \n",
    "                    else:\n",
    "                        image = pygame.image.load(\"right_pac.png\")\n",
    "                    image = pygame.transform.scale(image, (cell_size, cell_size))\n",
    "                    screen.blit(image, (y * cell_size, x * cell_size))\n",
    "                    pygame.display.update()\n",
    "                if x == self.ghost_row and y == self.ghost_col:\n",
    "                    if cell_color == WHITE:\n",
    "                        image = pygame.image.load(\"white.png\")\n",
    "                    if cell_color == BLACK:\n",
    "                        image = pygame.image.load(\"black.png\")\n",
    "                    if cell_color == BLUE:\n",
    "                        image = pygame.image.load(\"blue.png\")\n",
    "                    image = pygame.transform.scale(image, (cell_size, cell_size))\n",
    "                    screen.blit(image, (y * cell_size, x * cell_size))\n",
    "                    pygame.display.update()\n",
    "        last_x = self.current_row\n",
    "        last_y = self.current_col\n",
    "        pygame.display.flip()\n",
    "        if self.current_col == last_food:\n",
    "            iterate_last_food += 1\n",
    "        else:\n",
    "          iterate_last_food = 0\n",
    "          last_food = self.current_col\n",
    "        if iterate_last_food >= 30:\n",
    "          self.epsilon = 0.5\n",
    "        else:\n",
    "          self.epsilon = 0\n",
    "        time.sleep(0.5)\n",
    "        if self.current_col == self.ghost_col and self.current_row == self.ghost_row:\n",
    "            print('Loose Game!')\n",
    "            break\n",
    "    else:\n",
    "      print('Win Game!')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Game using Map1, gamma=0.25 and alpha=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win Game!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  game = Env(7, 9, 0.25, 0.2)\n",
    "  game.add_wall(np.array([[1, 1], [1, 2], [1, 3], [2, 1], [4, 1], [5, 1], [3, 3], [4, 3], [5, 4], [4, 5], [3, 5], [1, 5], [1, 6], [1, 7], [2, 7], [4, 7], [5, 7]]))\n",
    "  game.add_ghost(4, 4)\n",
    "  game.game()\n",
    "  game.test_game()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
